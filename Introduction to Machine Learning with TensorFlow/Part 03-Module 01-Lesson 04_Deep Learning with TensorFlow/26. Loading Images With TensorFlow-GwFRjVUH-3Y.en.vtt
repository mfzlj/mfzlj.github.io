WEBVTT
Kind: captions
Language: en

00:00:00.000 --> 00:00:03.810
Now let's look into loading image data with TensorFlow.

00:00:03.810 --> 00:00:07.890
Before, we were using TensorFlow Datasets to load our data.

00:00:07.890 --> 00:00:13.185
However, there might be times where we already have our own datasets saved locally.

00:00:13.185 --> 00:00:15.780
So in this notebook, we're going to learn how to load

00:00:15.780 --> 00:00:18.120
a dataset from our local disk and use

00:00:18.120 --> 00:00:21.180
the ImageDataGenerator class to generate batches

00:00:21.180 --> 00:00:25.305
of images and perform real-time image augmentation.

00:00:25.305 --> 00:00:27.495
In the previous notebooks,

00:00:27.495 --> 00:00:30.300
we also we're working with fairly artificial image

00:00:30.300 --> 00:00:33.890
datasets that we probably wouldn't use in real projects.

00:00:33.890 --> 00:00:36.530
In practice, we'll likely be dealing with

00:00:36.530 --> 00:00:40.370
full-sized color images like those we get from smartphones.

00:00:40.370 --> 00:00:45.485
So here we're going to use the Dogs vs Cats dataset available from Kaggle.

00:00:45.485 --> 00:00:47.210
Here's a couple examples images,

00:00:47.210 --> 00:00:49.765
one of the dog and one of the cat.

00:00:49.765 --> 00:00:55.805
We'll use this data set to train a neural network that can differentiate between the two.

00:00:55.805 --> 00:01:00.080
Now these days it doesn't seem like that big of an accomplishment,

00:01:00.080 --> 00:01:02.345
but even just a few short years ago,

00:01:02.345 --> 00:01:06.395
it was a pretty serious challenge for computer vision systems.

00:01:06.395 --> 00:01:09.350
So to get started, let's first download

00:01:09.350 --> 00:01:12.710
the filtered Dogs vs Cats dataset to our local disk.

00:01:12.710 --> 00:01:17.900
To do this, we can use a utility function with tf.keras and get_file

00:01:17.900 --> 00:01:23.045
that's just going to take in a filename where we want to save it to,

00:01:23.045 --> 00:01:24.515
as well as the origin,

00:01:24.515 --> 00:01:28.505
which is the URL from where to get the dataset.

00:01:28.505 --> 00:01:33.305
So by default, this is downloaded to a cache directory

00:01:33.305 --> 00:01:38.650
of keras/datasets and given the file name fname.

00:01:38.650 --> 00:01:42.335
However, if we update that to say sample.txt,

00:01:42.335 --> 00:01:45.670
that's instead where our data's going to get saved.

00:01:45.670 --> 00:01:50.355
Note also that this -/ refers to the current user's home folder.

00:01:50.355 --> 00:01:56.215
Again, origin parameter is just a string containing the original URL of the file.

00:01:56.215 --> 00:02:00.625
So here we've used this to go ahead and download our dataset.

00:02:00.625 --> 00:02:06.470
We also use extract equals true to extract the file as a zip archive.

00:02:06.470 --> 00:02:11.335
So this dataset we just downloaded it has the following directory structure.

00:02:11.335 --> 00:02:15.160
Notice that it's already split out between training and validation sets,

00:02:15.160 --> 00:02:18.350
as well as between cat and dog images.

00:02:18.350 --> 00:02:24.440
So we don't have to do any further splitting just related to training versus validation.

00:02:24.970 --> 00:02:28.955
In this cell, I've just used the OS library.

00:02:28.955 --> 00:02:33.775
They can get our different directory names to set up the directories

00:02:33.775 --> 00:02:39.470
for our different training sets and validation sets so that we can use them later on.

00:02:42.320 --> 00:02:46.970
Now, it's always important to explore the dataset before we get into training.

00:02:46.970 --> 00:02:50.450
So again, we're just using a pretty small subset of this data.

00:02:50.450 --> 00:02:53.660
So you'll see that there's 2,000 training images,

00:02:53.660 --> 00:02:59.690
1,000 validation images and that is split evenly between our cat and dog images.

00:02:59.690 --> 00:03:03.750
That's also always an important thing to consider is whether a dataset is balanced,

00:03:03.750 --> 00:03:08.510
and in this case, we have equal amount of images between the two classes.

00:03:08.510 --> 00:03:10.940
Let's go ahead and put an image from

00:03:10.940 --> 00:03:14.645
our dataset so that you can actually see what it looks like.

00:03:14.645 --> 00:03:17.300
However, in order to plot these images,

00:03:17.300 --> 00:03:20.250
we want to create a pipeline first.

00:03:20.810 --> 00:03:23.265
So to set this up,

00:03:23.265 --> 00:03:27.360
we're going to use our ImageDataGenerator class I mentioned earlier.

00:03:27.360 --> 00:03:31.895
This will help us be able to apply various transformations to our images,

00:03:31.895 --> 00:03:36.845
such as rotations, horizontal and vertical flips etc,

00:03:36.845 --> 00:03:39.430
that can better generalize the model on this data.

00:03:39.430 --> 00:03:42.860
So even though we have only 1,000 images of each class,

00:03:42.860 --> 00:03:48.005
we can end up having a lot more in practice by using these different transformations.

00:03:48.005 --> 00:03:52.260
We'll get a little bit more into these transformations later on.

00:03:52.700 --> 00:03:55.805
Once we have our generator here,

00:03:55.805 --> 00:03:57.920
we want to use the flow from

00:03:57.920 --> 00:04:02.405
directory function to load our images into a given directory.

00:04:02.405 --> 00:04:06.050
Note that this function can take various parameters such as the batch size,

00:04:06.050 --> 00:04:07.720
whether to shuffle our images are not,

00:04:07.720 --> 00:04:10.470
as well as the desired shape of our images.

00:04:10.470 --> 00:04:13.250
Now it's important to note that by default,

00:04:13.250 --> 00:04:20.605
this directory will use a batch size of 32 and resize all images to 256 by 256.

00:04:20.605 --> 00:04:22.615
In our case actually,

00:04:22.615 --> 00:04:28.225
we're going to use a batch size of 64 as well as an image shape of 224.

00:04:28.225 --> 00:04:31.070
This is because the network that we're going to use,

00:04:31.070 --> 00:04:32.755
that's a pre-trained network,

00:04:32.755 --> 00:04:37.195
takes an input of 224 by 224 images.

00:04:37.195 --> 00:04:40.845
We'll also do some of the techniques we use before

00:04:40.845 --> 00:04:44.530
such as rescaling our images to be between zero and one.

00:04:44.530 --> 00:04:47.390
Again, we'll feed in our batch size down here,

00:04:47.390 --> 00:04:51.760
our target size, and we'll make sure that our data, it get shuffled.

00:04:51.760 --> 00:04:57.425
This last piece on the class mode that set the binary is because we have two classes,

00:04:57.425 --> 00:04:58.610
a dog and a cat,

00:04:58.610 --> 00:05:03.710
and so we only need to have a zero or a one based on whether it's a dog or a cat class,

00:05:03.710 --> 00:05:05.450
and we don't have to use

00:05:05.450 --> 00:05:10.580
a wider class mode such as we used before when we had 10 classes.

00:05:10.580 --> 00:05:14.845
So here's an example image. This just has a cat.

00:05:14.845 --> 00:05:19.585
Again, we have 2,000 images belonging to two classes.

00:05:19.585 --> 00:05:26.250
Next, we'll come back and start looking into our different data augmentation strategies.

